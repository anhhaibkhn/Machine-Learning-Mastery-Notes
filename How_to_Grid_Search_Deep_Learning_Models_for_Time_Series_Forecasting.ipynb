{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to Grid Search Deep Learning Models for Time Series Forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNb34iisyBHrdhqH8Ecughl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhhaibkhn/Machine-Learning-Mastery-Notes/blob/master/How_to_Grid_Search_Deep_Learning_Models_for_Time_Series_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5QoMOVqndRX",
        "colab_type": "text"
      },
      "source": [
        "## How to develop a framework to grid search `hyperparameters` for deep learning models - [Source](https://machinelearningmastery.com/how-to-grid-search-deep-learning-models-for-time-series-forecasting/)\n",
        "\n",
        "What to learn:\n",
        "\n",
        "* How to develop `a generic grid searching framework` for tuning model hyperparameters.\n",
        "* How to `grid search hyperparameters` for a `Multilayer Perceptron` model on the airline passengers univariate time series forecasting problem.\n",
        "* How to adapt the framework to grid search hyperparameters for `convolutional` and `long short-term memory` neural networks.\n",
        "\n",
        "Overview:\n",
        "\n",
        "1. Time Series Problem\n",
        "2. Grid Search Framework\n",
        "3. Grid Search Multilayer Perceptron\n",
        "4. Grid Search Convolutional Neural Network\n",
        "5. Grid Search Long Short-Term Memory Networ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP7eeCGRorwI",
        "colab_type": "text"
      },
      "source": [
        "### 1. Time Series Problem\n",
        "\n",
        "- [Dataset](https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv)  filename ‘monthly-airline-passengers.csv‘ \n",
        "\n",
        "- The dataset is monthly and has `12 years`, or `144 observation`s. In our testing, we will use the `last year`, or `12 observations`, as the test set.\n",
        "\n",
        "- A line plot is created. The dataset has an obvious trend and seasonal component. The period of the seasonal component is 12 months."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJNeNwiolWkC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ceef50d4-f53b-4cce-a793-a3cb07c317d3"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "\n",
        "# load\n",
        "series = pd.read_csv(url, header=0, index_col=0)\n",
        "\n",
        "# summarize shape\n",
        "print(series.shape)\n",
        "# plot\n",
        "plt.plot(series)\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(144, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GxY-vR5rJb7",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, we will introduce the t`ools for grid searching`, but we will not optimize the model hyperparameters for this problem. Instead, we will demonstrate how to grid search the deep learning model hyperparameters generally and find models with some skill compared to a naive mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZKlYLSOsOFb",
        "colab_type": "text"
      },
      "source": [
        "### 2. Grid Search Framework\n",
        "\n",
        "* Train-Test Split\n",
        "* Series as Supervised Learning\n",
        "* Walk-Forward Validation\n",
        "* Repeat Evaluation\n",
        "* Summarize Performance\n",
        "* Worked Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd9fmsh6pki-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a82b089d-c352-4b9e-f364-fe6dc2cde5d6"
      },
      "source": [
        "# grid search persistence models for airline passengers\n",
        "from math import sqrt\n",
        "from numpy import mean\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# split a univariate dataset into train/test sets\n",
        "def train_test_split(data, n_test):\n",
        "\treturn data[:-n_test], data[-n_test:]\n",
        "\n",
        "# root mean squared error or rmse\n",
        "def measure_rmse(actual, predicted):\n",
        "\treturn sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# fit a model\n",
        "def model_fit(train, config):\n",
        "\treturn None\n",
        "\n",
        "# forecast with a pre-fit model\n",
        "def model_predict(model, history, offset):\n",
        "\treturn history[-offset]\n",
        "\n",
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, n_test, cfg):\n",
        "\tpredictions = list()\n",
        "\t# split dataset\n",
        "\ttrain, test = train_test_split(data, n_test)\n",
        "\t# fit model\n",
        "\tmodel = model_fit(train, cfg)\n",
        "\t# seed history with training dataset\n",
        "\thistory = [x for x in train]\n",
        "\t# step over each time-step in the test set\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# fit model and make forecast for history\n",
        "\t\tyhat = model_predict(model, history, cfg)\n",
        "\t\t# store forecast in list of predictions\n",
        "\t\tpredictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "\t\thistory.append(test[i])\n",
        "\t# estimate prediction error\n",
        "\terror = measure_rmse(test, predictions)\n",
        "\tprint(' > %.3f' % error)\n",
        "\treturn error\n",
        "\n",
        "# score a model, return None on failure\n",
        "def repeat_evaluate(data, config, n_test, n_repeats=10):\n",
        "\t# convert config to a key\n",
        "\tkey = str(config)\n",
        "\t# fit and evaluate the model n times\n",
        "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
        "\t# summarize score\n",
        "\tresult = mean(scores)\n",
        "\tprint('> Model[%s] %.3f' % (key, result))\n",
        "\treturn (key, result)\n",
        "\n",
        "# grid search configs\n",
        "def grid_search(data, cfg_list, n_test):\n",
        "\t# evaluate configs\n",
        "\tscores = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
        "\t# sort configs by error, asc\n",
        "\tscores.sort(key=lambda tup: tup[1])\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "# series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0)\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "series = pd.read_csv(url, header=0, index_col=0)\n",
        "\n",
        "data = series.values\n",
        "# data split\n",
        "n_test = 12\n",
        "# model configs\n",
        "cfg_list = [1, 6, 12, 24, 36]\n",
        "# grid search\n",
        "scores = grid_search(data, cfg_list, n_test)\n",
        "print('done')\n",
        "# list top 10 configs\n",
        "for cfg, error in scores[:10]:\n",
        "\tprint(cfg, error)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > 53.152\n",
            " > 53.152\n",
            " > 53.152\n",
            " > 53.152\n",
            " > 53.152\n",
            " > 53.152\n",
            " > 53.152\n",
            " > 53.152\n",
            " > 53.152\n",
            " > 53.152\n",
            "> Model[1] 53.152\n",
            " > 126.735\n",
            " > 126.735\n",
            " > 126.735\n",
            " > 126.735\n",
            " > 126.735\n",
            " > 126.735\n",
            " > 126.735\n",
            " > 126.735\n",
            " > 126.735\n",
            " > 126.735\n",
            "> Model[6] 126.735\n",
            " > 50.708\n",
            " > 50.708\n",
            " > 50.708\n",
            " > 50.708\n",
            " > 50.708\n",
            " > 50.708\n",
            " > 50.708\n",
            " > 50.708\n",
            " > 50.708\n",
            " > 50.708\n",
            "> Model[12] 50.708\n",
            " > 97.110\n",
            " > 97.110\n",
            " > 97.110\n",
            " > 97.110\n",
            " > 97.110\n",
            " > 97.110\n",
            " > 97.110\n",
            " > 97.110\n",
            " > 97.110\n",
            " > 97.110\n",
            "> Model[24] 97.110\n",
            " > 110.274\n",
            " > 110.274\n",
            " > 110.274\n",
            " > 110.274\n",
            " > 110.274\n",
            " > 110.274\n",
            " > 110.274\n",
            " > 110.274\n",
            " > 110.274\n",
            " > 110.274\n",
            "> Model[36] 110.274\n",
            "done\n",
            "12 50.708316214732804\n",
            "1 53.1515129919491\n",
            "24 97.10990337413241\n",
            "36 110.27352356753639\n",
            "6 126.73495965991387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cgzJjw4saZR",
        "colab_type": "text"
      },
      "source": [
        "### 3. Grid Search Multilayer Perceptron\n",
        "\n",
        "* n_input: The number of prior inputs to use as input for the model (e.g. 12 months).\n",
        "* n_nodes: The number of nodes to use in the hidden layer (e.g. 50).\n",
        "* n_epochs: The number of training epochs (e.g. 1000).\n",
        "* n_batch: The number of samples to include in each mini-batch (e.g. 32).\n",
        "* n_diff: The difference order (e.g. 0 or 12)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg5-0Plurs2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f40ed42a-c68b-41cc-b4c3-be5179845989"
      },
      "source": [
        "# grid search mlps for airline passengers\n",
        "from math import sqrt\n",
        "from numpy import array\n",
        "from numpy import mean\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# split a univariate dataset into train/test sets\n",
        "def train_test_split(data, n_test):\n",
        "\treturn data[:-n_test], data[-n_test:]\n",
        "\n",
        "# transform list into supervised learning format\n",
        "def series_to_supervised(data, n_in=1, n_out=1):\n",
        "\tdf = DataFrame(data)\n",
        "\tcols = list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\t# drop rows with NaN values\n",
        "\tagg.dropna(inplace=True)\n",
        "\treturn agg.values\n",
        "\n",
        "# root mean squared error or rmse\n",
        "def measure_rmse(actual, predicted):\n",
        "\treturn sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# difference dataset\n",
        "def difference(data, order):\n",
        "\treturn [data[i] - data[i - order] for i in range(order, len(data))]\n",
        "\n",
        "# fit a model\n",
        "def model_fit(train, config):\n",
        "\t# unpack config\n",
        "\tn_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
        "\t# prepare data\n",
        "\tif n_diff > 0:\n",
        "\t\ttrain = difference(train, n_diff)\n",
        "\t# transform series into supervised format\n",
        "\tdata = series_to_supervised(train, n_in=n_input)\n",
        "\t# separate inputs and outputs\n",
        "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(n_nodes, activation='relu', input_dim=n_input))\n",
        "\tmodel.add(Dense(1))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit model\n",
        "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
        "\treturn model\n",
        "\n",
        "# forecast with the fit model\n",
        "def model_predict(model, history, config):\n",
        "\t# unpack config\n",
        "\tn_input, _, _, _, n_diff = config\n",
        "\t# prepare data\n",
        "\tcorrection = 0.0\n",
        "\tif n_diff > 0:\n",
        "\t\tcorrection = history[-n_diff]\n",
        "\t\thistory = difference(history, n_diff)\n",
        "\t# shape input for model\n",
        "\tx_input = array(history[-n_input:]).reshape((1, n_input))\n",
        "\t# make forecast\n",
        "\tyhat = model.predict(x_input, verbose=0)\n",
        "\t# correct forecast if it was differenced\n",
        "\treturn correction + yhat[0]\n",
        "\n",
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, n_test, cfg):\n",
        "\tpredictions = list()\n",
        "\t# split dataset\n",
        "\ttrain, test = train_test_split(data, n_test)\n",
        "\t# fit model\n",
        "\tmodel = model_fit(train, cfg)\n",
        "\t# seed history with training dataset\n",
        "\thistory = [x for x in train]\n",
        "\t# step over each time-step in the test set\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# fit model and make forecast for history\n",
        "\t\tyhat = model_predict(model, history, cfg)\n",
        "\t\t# store forecast in list of predictions\n",
        "\t\tpredictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "\t\thistory.append(test[i])\n",
        "\t# estimate prediction error\n",
        "\terror = measure_rmse(test, predictions)\n",
        "\tprint(' > %.3f' % error)\n",
        "\treturn error\n",
        "\n",
        "# score a model, return None on failure\n",
        "def repeat_evaluate(data, config, n_test, n_repeats=10):\n",
        "\t# convert config to a key\n",
        "\tkey = str(config)\n",
        "\t# fit and evaluate the model n times\n",
        "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
        "\t# summarize score\n",
        "\tresult = mean(scores)\n",
        "\tprint('> Model[%s] %.3f' % (key, result))\n",
        "\treturn (key, result)\n",
        "\n",
        "# grid search configs\n",
        "def grid_search(data, cfg_list, n_test):\n",
        "\t# evaluate configs\n",
        "\tscores = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
        "\t# sort configs by error, asc\n",
        "\tscores.sort(key=lambda tup: tup[1])\n",
        "\treturn scores\n",
        "\n",
        "# create a list of configs to try\n",
        "def model_configs():\n",
        "\t# define scope of configs\n",
        "\tn_input = [12]\n",
        "\tn_nodes = [50, 100]\n",
        "\tn_epochs = [100]\n",
        "\tn_batch = [1, 150]\n",
        "\tn_diff = [0, 12]\n",
        "\t# create configs\n",
        "\tconfigs = list()\n",
        "\tfor i in n_input:\n",
        "\t\tfor j in n_nodes:\n",
        "\t\t\tfor k in n_epochs:\n",
        "\t\t\t\tfor l in n_batch:\n",
        "\t\t\t\t\tfor m in n_diff:\n",
        "\t\t\t\t\t\tcfg = [i, j, k, l, m]\n",
        "\t\t\t\t\t\tconfigs.append(cfg)\n",
        "\tprint('Total configs: %d' % len(configs))\n",
        "\treturn configs\n",
        "\n",
        "# define dataset\n",
        "# series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0)\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "series = pd.read_csv(url, header=0, index_col=0)\n",
        "data = series.values\n",
        "# data split\n",
        "n_test = 12\n",
        "# model configs\n",
        "cfg_list = model_configs()\n",
        "# grid search\n",
        "scores = grid_search(data, cfg_list, n_test)\n",
        "print('done')\n",
        "# list top 3 configs\n",
        "for cfg, error in scores[:3]:\n",
        "\tprint(cfg, error)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total configs: 8\n",
            " > 25.644\n",
            " > 22.437\n",
            " > 17.489\n",
            " > 27.822\n",
            " > 19.192\n",
            " > 17.197\n",
            " > 25.273\n",
            " > 22.596\n",
            " > 20.946\n",
            " > 25.940\n",
            "> Model[[12, 50, 100, 1, 0]] 22.454\n",
            " > 21.269\n",
            " > 20.049\n",
            " > 20.612\n",
            " > 19.473\n",
            " > 21.815\n",
            " > 18.263\n",
            " > 19.072\n",
            " > 19.765\n",
            " > 22.189\n",
            " > 20.788\n",
            "> Model[[12, 50, 100, 1, 12]] 20.329\n",
            " > 43.745\n",
            " > 80.342\n",
            " > 57.575\n",
            " > 29.581\n",
            " > 71.344\n",
            " > 63.395\n",
            " > 91.728\n",
            " > 77.317\n",
            " > 63.083\n",
            " > 23.079\n",
            "> Model[[12, 50, 100, 150, 0]] 60.119\n",
            " > 17.429\n",
            " > 20.912\n",
            " > 18.126\n",
            " > 18.891\n",
            " > 19.734\n",
            " > 18.876\n",
            " > 21.052\n",
            " > 19.256\n",
            " > 21.411\n",
            " > 18.041\n",
            "> Model[[12, 50, 100, 150, 12]] 19.373\n",
            " > 25.916\n",
            " > 24.010\n",
            " > 24.205\n",
            " > 20.943\n",
            " > 20.921\n",
            " > 18.780\n",
            " > 19.388\n",
            " > 16.436\n",
            " > 16.846\n",
            " > 16.361\n",
            "> Model[[12, 100, 100, 1, 0]] 20.381\n",
            " > 19.018\n",
            " > 20.638\n",
            " > 17.163\n",
            " > 20.504\n",
            " > 18.533\n",
            " > 20.067\n",
            " > 19.142\n",
            " > 19.913\n",
            " > 19.772\n",
            " > 20.364\n",
            "> Model[[12, 100, 100, 1, 12]] 19.511\n",
            " > 42.532\n",
            " > 40.533\n",
            " > 73.005\n",
            " > 53.644\n",
            " > 77.457\n",
            " > 47.065\n",
            " > 50.787\n",
            " > 47.670\n",
            " > 68.286\n",
            " > 67.953\n",
            "> Model[[12, 100, 100, 150, 0]] 56.893\n",
            " > 18.981\n",
            " > 19.171\n",
            " > 20.118\n",
            " > 19.246\n",
            " > 18.659\n",
            " > 19.301\n",
            " > 18.808\n",
            " > 20.945\n",
            " > 19.903\n",
            " > 19.627\n",
            "> Model[[12, 100, 100, 150, 12]] 19.476\n",
            "done\n",
            "[12, 50, 100, 150, 12] 19.372852970943104\n",
            "[12, 100, 100, 150, 12] 19.475914130670166\n",
            "[12, 100, 100, 1, 12] 19.511444594020894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ5inWZSszKb",
        "colab_type": "text"
      },
      "source": [
        "### 4. Grid Search Convolutional Neural Network\n",
        "\n",
        "The chosen set of hyperparameters to grid search in the CNN model are as follows:\n",
        "\n",
        "* n_input: The number of prior inputs to use as input for the model (e.g. 12 months).\n",
        "* n_filters: The number of filter maps in the convolutional layer (e.g. 32).\n",
        "* n_kernel: The kernel size in the convolutional layer (e.g. 3).\n",
        "* n_epochs: The number of training epochs (e.g. 1000).\n",
        "* n_batch: The number of samples to include in each mini-batch (e.g. 32).\n",
        "* n_diff: The difference order (e.g. 0 or 12)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkIw6jCLsm81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42b78a58-bb88-4aec-db86-d9841d07b9ca"
      },
      "source": [
        "# grid search cnn for airline passengers\n",
        "from math import sqrt\n",
        "from numpy import array\n",
        "from numpy import mean\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "# split a univariate dataset into train/test sets\n",
        "def train_test_split(data, n_test):\n",
        "\treturn data[:-n_test], data[-n_test:]\n",
        "\n",
        "# transform list into supervised learning format\n",
        "def series_to_supervised(data, n_in=1, n_out=1):\n",
        "\tdf = DataFrame(data)\n",
        "\tcols = list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\t# drop rows with NaN values\n",
        "\tagg.dropna(inplace=True)\n",
        "\treturn agg.values\n",
        "\n",
        "# root mean squared error or rmse\n",
        "def measure_rmse(actual, predicted):\n",
        "\treturn sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# difference dataset\n",
        "def difference(data, order):\n",
        "\treturn [data[i] - data[i - order] for i in range(order, len(data))]\n",
        "\n",
        "# fit a model\n",
        "def model_fit(train, config):\n",
        "\t# unpack config\n",
        "\tn_input, n_filters, n_kernel, n_epochs, n_batch, n_diff = config\n",
        "\t# prepare data\n",
        "\tif n_diff > 0:\n",
        "\t\ttrain = difference(train, n_diff)\n",
        "\t# transform series into supervised format\n",
        "\tdata = series_to_supervised(train, n_in=n_input)\n",
        "\t# separate inputs and outputs\n",
        "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n",
        "\t# reshape input data into [samples, timesteps, features]\n",
        "\tn_features = 1\n",
        "\ttrain_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(n_input, n_features)))\n",
        "\tmodel.add(MaxPooling1D(pool_size=2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit\n",
        "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
        "\treturn model\n",
        "\n",
        "# forecast with the fit model\n",
        "def model_predict(model, history, config):\n",
        "\t# unpack config\n",
        "\tn_input, _, _, _, _, n_diff = config\n",
        "\t# prepare data\n",
        "\tcorrection = 0.0\n",
        "\tif n_diff > 0:\n",
        "\t\tcorrection = history[-n_diff]\n",
        "\t\thistory = difference(history, n_diff)\n",
        "\tx_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
        "\t# forecast\n",
        "\tyhat = model.predict(x_input, verbose=0)\n",
        "\treturn correction + yhat[0]\n",
        "\n",
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, n_test, cfg):\n",
        "\tpredictions = list()\n",
        "\t# split dataset\n",
        "\ttrain, test = train_test_split(data, n_test)\n",
        "\t# fit model\n",
        "\tmodel = model_fit(train, cfg)\n",
        "\t# seed history with training dataset\n",
        "\thistory = [x for x in train]\n",
        "\t# step over each time-step in the test set\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# fit model and make forecast for history\n",
        "\t\tyhat = model_predict(model, history, cfg)\n",
        "\t\t# store forecast in list of predictions\n",
        "\t\tpredictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "\t\thistory.append(test[i])\n",
        "\t# estimate prediction error\n",
        "\terror = measure_rmse(test, predictions)\n",
        "\tprint(' > %.3f' % error)\n",
        "\treturn error\n",
        "\n",
        "# score a model, return None on failure\n",
        "def repeat_evaluate(data, config, n_test, n_repeats=10):\n",
        "\t# convert config to a key\n",
        "\tkey = str(config)\n",
        "\t# fit and evaluate the model n times\n",
        "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
        "\t# summarize score\n",
        "\tresult = mean(scores)\n",
        "\tprint('> Model[%s] %.3f' % (key, result))\n",
        "\treturn (key, result)\n",
        "\n",
        "# grid search configs\n",
        "def grid_search(data, cfg_list, n_test):\n",
        "\t# evaluate configs\n",
        "\tscores = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
        "\t# sort configs by error, asc\n",
        "\tscores.sort(key=lambda tup: tup[1])\n",
        "\treturn scores\n",
        "\n",
        "# create a list of configs to try\n",
        "def model_configs():\n",
        "\t# define scope of configs\n",
        "\tn_input = [12]\n",
        "\tn_filters = [64]\n",
        "\tn_kernels = [3, 5]\n",
        "\tn_epochs = [100]\n",
        "\tn_batch = [1, 150]\n",
        "\tn_diff = [0, 12]\n",
        "\t# create configs\n",
        "\tconfigs = list()\n",
        "\tfor a in n_input:\n",
        "\t\tfor b in n_filters:\n",
        "\t\t\tfor c in n_kernels:\n",
        "\t\t\t\tfor d in n_epochs:\n",
        "\t\t\t\t\tfor e in n_batch:\n",
        "\t\t\t\t\t\tfor f in n_diff:\n",
        "\t\t\t\t\t\t\tcfg = [a,b,c,d,e,f]\n",
        "\t\t\t\t\t\t\tconfigs.append(cfg)\n",
        "\tprint('Total configs: %d' % len(configs))\n",
        "\treturn configs\n",
        "\n",
        "# define dataset\n",
        "# series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0)\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "series = pd.read_csv(url, header=0, index_col=0)\n",
        "data = series.values\n",
        "\n",
        "# data split\n",
        "n_test = 12\n",
        "# model configs\n",
        "cfg_list = model_configs()\n",
        "# grid search\n",
        "scores = grid_search(data, cfg_list, n_test)\n",
        "print('done')\n",
        "# list top 10 configs\n",
        "for cfg, error in scores[:3]:\n",
        "\tprint(cfg, error)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total configs: 8\n",
            " > 37.631\n",
            " > 16.832\n",
            " > 26.690\n",
            " > 17.805\n",
            " > 17.017\n",
            " > 16.539\n",
            " > 20.637\n",
            " > 17.346\n",
            " > 19.508\n",
            " > 20.067\n",
            "> Model[[12, 64, 3, 100, 1, 0]] 21.007\n",
            " > 19.297\n",
            " > 20.156\n",
            " > 21.370\n",
            " > 20.609\n",
            " > 18.777\n",
            " > 22.055\n",
            " > 20.454\n",
            " > 21.073\n",
            " > 20.096\n",
            " > 20.711\n",
            "> Model[[12, 64, 3, 100, 1, 12]] 20.460\n",
            " > 75.132\n",
            " > 87.957\n",
            " > 78.806\n",
            " > 85.172\n",
            " > 79.355\n",
            " > 81.527\n",
            " > 79.462\n",
            " > 73.727\n",
            " > 68.296\n",
            " > 73.533\n",
            "> Model[[12, 64, 3, 100, 150, 0]] 78.297\n",
            " > 18.668\n",
            " > 19.348\n",
            " > 17.962\n",
            " > 18.892\n",
            " > 19.835\n",
            " > 18.828\n",
            " > 19.012\n",
            " > 17.887\n",
            " > 18.649\n",
            " > 20.219\n",
            "> Model[[12, 64, 3, 100, 150, 12]] 18.930\n",
            " > 21.269\n",
            " > 25.380\n",
            " > 31.234\n",
            " > 18.035\n",
            " > 18.854\n",
            " > 29.764\n",
            " > 20.044\n",
            " > 18.196\n",
            " > 19.716\n",
            " > 19.408\n",
            "> Model[[12, 64, 5, 100, 1, 0]] 22.190\n",
            " > 17.775\n",
            " > 19.020\n",
            " > 19.271\n",
            " > 18.115\n",
            " > 19.588\n",
            " > 18.654\n",
            " > 20.049\n",
            " > 19.624\n",
            " > 19.091\n",
            " > 18.507\n",
            "> Model[[12, 64, 5, 100, 1, 12]] 18.969\n",
            " > 73.491\n",
            " > 87.211\n",
            " > 74.136\n",
            " > 72.863\n",
            " > 82.885\n",
            " > 88.219\n",
            " > 86.279\n",
            " > 90.976\n",
            " > 70.185\n",
            " > 79.105\n",
            "> Model[[12, 64, 5, 100, 150, 0]] 80.535\n",
            " > 20.715\n",
            " > 19.131\n",
            " > 20.123\n",
            " > 19.789\n",
            " > 20.263\n",
            " > 18.945\n",
            " > 20.894\n",
            " > 19.875\n",
            " > 18.473\n",
            " > 20.174\n",
            "> Model[[12, 64, 5, 100, 150, 12]] 19.838\n",
            "done\n",
            "[12, 64, 3, 100, 150, 12] 18.929970351734617\n",
            "[12, 64, 5, 100, 1, 12] 18.96942067532511\n",
            "[12, 64, 5, 100, 150, 12] 19.83832320799812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TDCJ4kGtJGU",
        "colab_type": "text"
      },
      "source": [
        "### 5. Grid Search Long Short-Term Memory Network\n",
        "\n",
        "* n_input: The number of prior inputs to use as input for the model (e.g. 12 months).\n",
        "* n_nodes: The number of nodes to use in the hidden layer (e.g. 50).\n",
        "* n_epochs: The number of training epochs (e.g. 1000).\n",
        "* n_batch: The number of samples to include in each mini-batch (e.g. 32).\n",
        "* n_diff: The difference order (e.g. 0 or 12)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkwkgWEUtO80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grid search lstm for airline passengers\n",
        "from math import sqrt\n",
        "from numpy import array\n",
        "from numpy import mean\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "# split a univariate dataset into train/test sets\n",
        "def train_test_split(data, n_test):\n",
        "\treturn data[:-n_test], data[-n_test:]\n",
        "\n",
        "# transform list into supervised learning format\n",
        "def series_to_supervised(data, n_in=1, n_out=1):\n",
        "\tdf = DataFrame(data)\n",
        "\tcols = list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\t# drop rows with NaN values\n",
        "\tagg.dropna(inplace=True)\n",
        "\treturn agg.values\n",
        "\n",
        "# root mean squared error or rmse\n",
        "def measure_rmse(actual, predicted):\n",
        "\treturn sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# difference dataset\n",
        "def difference(data, order):\n",
        "\treturn [data[i] - data[i - order] for i in range(order, len(data))]\n",
        "\n",
        "# fit a model\n",
        "def model_fit(train, config):\n",
        "\t# unpack config\n",
        "\tn_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
        "\t# prepare data\n",
        "\tif n_diff > 0:\n",
        "\t\ttrain = difference(train, n_diff)\n",
        "\t# transform series into supervised format\n",
        "\tdata = series_to_supervised(train, n_in=n_input)\n",
        "\t# separate inputs and outputs\n",
        "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n",
        "\t# reshape input data into [samples, timesteps, features]\n",
        "\tn_features = 1\n",
        "\ttrain_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(n_nodes, activation='relu', input_shape=(n_input, n_features)))\n",
        "\tmodel.add(Dense(n_nodes, activation='relu'))\n",
        "\tmodel.add(Dense(1))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit model\n",
        "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
        "\treturn model\n",
        "\n",
        "# forecast with the fit model\n",
        "def model_predict(model, history, config):\n",
        "\t# unpack config\n",
        "\tn_input, _, _, _, n_diff = config\n",
        "\t# prepare data\n",
        "\tcorrection = 0.0\n",
        "\tif n_diff > 0:\n",
        "\t\tcorrection = history[-n_diff]\n",
        "\t\thistory = difference(history, n_diff)\n",
        "\t# reshape sample into [samples, timesteps, features]\n",
        "\tx_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
        "\t# forecast\n",
        "\tyhat = model.predict(x_input, verbose=0)\n",
        "\treturn correction + yhat[0]\n",
        "\n",
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, n_test, cfg):\n",
        "\tpredictions = list()\n",
        "\t# split dataset\n",
        "\ttrain, test = train_test_split(data, n_test)\n",
        "\t# fit model\n",
        "\tmodel = model_fit(train, cfg)\n",
        "\t# seed history with training dataset\n",
        "\thistory = [x for x in train]\n",
        "\t# step over each time-step in the test set\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# fit model and make forecast for history\n",
        "\t\tyhat = model_predict(model, history, cfg)\n",
        "\t\t# store forecast in list of predictions\n",
        "\t\tpredictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "\t\thistory.append(test[i])\n",
        "\t# estimate prediction error\n",
        "\terror = measure_rmse(test, predictions)\n",
        "\tprint(' > %.3f' % error)\n",
        "\treturn error\n",
        "\n",
        "# score a model, return None on failure\n",
        "def repeat_evaluate(data, config, n_test, n_repeats=10):\n",
        "\t# convert config to a key\n",
        "\tkey = str(config)\n",
        "\t# fit and evaluate the model n times\n",
        "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
        "\t# summarize score\n",
        "\tresult = mean(scores)\n",
        "\tprint('> Model[%s] %.3f' % (key, result))\n",
        "\treturn (key, result)\n",
        "\n",
        "# grid search configs\n",
        "def grid_search(data, cfg_list, n_test):\n",
        "\t# evaluate configs\n",
        "\tscores = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
        "\t# sort configs by error, asc\n",
        "\tscores.sort(key=lambda tup: tup[1])\n",
        "\treturn scores\n",
        "\n",
        "# create a list of configs to try\n",
        "def model_configs():\n",
        "\t# define scope of configs\n",
        "\tn_input = [12]\n",
        "\tn_nodes = [100]\n",
        "\tn_epochs = [50]\n",
        "\tn_batch = [1, 150]\n",
        "\tn_diff = [12]\n",
        "\t# create configs\n",
        "\tconfigs = list()\n",
        "\tfor i in n_input:\n",
        "\t\tfor j in n_nodes:\n",
        "\t\t\tfor k in n_epochs:\n",
        "\t\t\t\tfor l in n_batch:\n",
        "\t\t\t\t\tfor m in n_diff:\n",
        "\t\t\t\t\t\tcfg = [i, j, k, l, m]\n",
        "\t\t\t\t\t\tconfigs.append(cfg)\n",
        "\tprint('Total configs: %d' % len(configs))\n",
        "\treturn configs\n",
        "\n",
        "# define dataset\n",
        "# series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0)\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "series = pd.read_csv(url, header=0, index_col=0)\n",
        "data = series.values\n",
        "# data split\n",
        "n_test = 12\n",
        "# model configs\n",
        "cfg_list = model_configs()\n",
        "# grid search\n",
        "scores = grid_search(data, cfg_list, n_test)\n",
        "print('done')\n",
        "# list top 10 configs\n",
        "for cfg, error in scores[:3]:\n",
        "\tprint(cfg, error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26-Lx8MEtlL7",
        "colab_type": "text"
      },
      "source": [
        "The model requires a lot more tuning and may do much better with a hybrid configuration, such as having a CNN model as input.\n",
        "\n",
        "We can unpack this configuration as:\n",
        "\n",
        "* n_input: 12\n",
        "* n_nodes: 100\n",
        "* n_epochs: 50\n",
        "* n_batch: 1\n",
        "* n_diff: 12\n",
        "\n",
        "\n",
        "#### [Further reading](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)"
      ]
    }
  ]
}