{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackingEnsembleMachineLearningWithPython.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMp9vvn0sHFCH+I6UNwGCIm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhhaibkhn/Machine-Learning-Mastery-Notes/blob/master/StackingEnsembleMachineLearningWithPython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jw1cFtec3QX",
        "colab_type": "text"
      },
      "source": [
        "### Stacking Ensemble Machine Learning With Python\n",
        "[Source](https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/)\n",
        "\n",
        "Stacking or stacked generalization is an ensemle ML algorithm.\n",
        "It uses meta-learning algorithm to learn **how to best combine the predictions from 2 or more base ML algorithms**. The benefit of stacking is that it can harness the capabilities of a range of well-performing models on a `calssifcation` or regression task and make better performance preidcitons than the single ones. \n",
        "\n",
        "#### Key points:\n",
        "* Stacking is an ensemble machine learning algorithm that learns how to best combine the predictions from multiple well-performing machine learning models.\n",
        "* The scikit-learn library provides a standard implementation of the stacking ensemble in Python.\n",
        "* How to use stacking ensembles for regression and classification predictive modeling.\n",
        "\n",
        "#### Overview\n",
        "\n",
        "1. Stacked Generalizatioin \n",
        "2. Stacking Scikit-Learn API\n",
        "3. Stacking for Classfication\n",
        "4. Stacking for Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CnrFBZYeaOj",
        "colab_type": "text"
      },
      "source": [
        "### 1. Stacked Generalization\n",
        "\n",
        "It involves combining the predictions from multiple machine learning models on the same dataset, like bagging and boosting.\n",
        "\n",
        "#### Stacking addresses the question:\n",
        "\n",
        "Given multiple machine learning models that are skillful on a problem, but in different ways, how do you choose which model to use (trust)?\n",
        "\n",
        "The approach to this question is to use another machine learning model that learns when to use or trust each model in the ensemble.\n",
        "\n",
        "#### Architecture \n",
        "\n",
        "#### Level-0 Models (Base-Models): \n",
        "\n",
        "* Models fit on the training data and whose predictions are compiled.\n",
        "\n",
        "* Base-models are often complex and diverse. As such, it is often a good idea to use a range of models that make very different assumptions about how to solve the predictive modeling task, such as linear models, decision trees, support vector machines, neural networks, and more. Other ensemble algorithms may also be used as base-models, such as random forests.\n",
        "\n",
        "* Base-Models: Use a diverse range of models that make different assumptions about the prediction task.\n",
        "\n",
        "Level-1 Model (Meta-Model)\n",
        "* Model that learns how to best combine the predictions of the base models.\n",
        "* The meta-model is often simple, providing a smooth interpretation of the predictions made by the base models. As such, linear models are often used as the meta-model, such as linear regression for regression tasks (predicting a numeric value) and logistic regression for classification tasks (predicting a class label).\n",
        "* Examples: Regression Meta-model like Linear Regression, Classfication Meta-model likes Logistic Regression\n",
        "\n",
        "\n",
        "The most common approach to preparing the training dataset for the meta-model is via [k-fold cross-validation](https://machinelearningmastery.com/k-fold-cross-validation/) of the base models, where the [out-of-fold predictions](https://machinelearningmastery.com/out-of-fold-predictions-in-machine-learning/) are used as the basis for the training dataset for the meta-model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkK7-oNDex5k",
        "colab_type": "text"
      },
      "source": [
        "### 2. Stacking Scikit-Learn API\n",
        "\n",
        "[Implementing stacking from scratch in Python tutorial.](https://machinelearningmastery.com/implementing-stacking-scratch-python/)\n",
        "\n",
        "[Implementing stacking from scratch for deep learning in Python tutorial.](https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/)\n",
        "\n",
        "The scikit-learn Python machine learning library provides an implementation of stacking for machine learning.\n",
        "\n",
        "It is available in version 0.22 of the library and higher\n",
        "Stacking is provided via the [StackingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html) and [StackingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html) classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXdHFI-tcpDB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f013e577-fe39-4d32-986e-e5452e25e082"
      },
      "source": [
        "\t# check scikit-learn version\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCIVawTMe1Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Define 2 level-0 models'''\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "models = [('lr',LogisticRegression()),('svm',SVC())] \n",
        "stacking = StackingClassifier(estimators=models)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeQm12xO_7Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Each model in the list may also be a Pipeline, \n",
        "including any data preparation required by the model prior to fitting the model on the training dataset'''\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "models = [('lr',LogisticRegression()),('svm',make_pipeline(StandardScaler(),SVC()))]\n",
        "stacking = StackingClassifier(estimators=models)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6zWXbF-Ohg8",
        "colab_type": "text"
      },
      "source": [
        "The dataset for the meta-model is prepared using cross-validation. By default,` 5-fold cross-validation` is used, although this can be changed via the “cv” argument and set to either a number (e.g. 10 for 10-fold cross-validation) or a cross-validation object (e.g. StratifiedKFold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNoV1Edge2oM",
        "colab_type": "text"
      },
      "source": [
        "#### 3. Stacking for Classification\n",
        "\n",
        "In this section, we will look at using stacking for a classification problem.\n",
        "\n",
        "First, we can use the [make_classification() function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) to create a synthetic binary classification problem with 1,000 examples and 20 input features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq6pDJsLAFgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7787cf69-5231-44c4-aae3-c02d4f9885e1"
      },
      "source": [
        "# test classification dataset\n",
        "from sklearn.datasets import make_classification\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 20) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNIb46KpDHC4",
        "colab_type": "text"
      },
      "source": [
        "Evaluating a suite of different machine learning models on the dataset.\n",
        "\n",
        "Specifically, we will evaluate the following five algorithms:\n",
        "\n",
        "* Logistic Regression.\n",
        "* k-Nearest Neighbors.\n",
        "* Decision Tree.\n",
        "* Support Vector Machine.\n",
        "* Naive Bayes.\n",
        "\n",
        "Each algorithm will be evaluated using default model hyperparameters. The function get_models() below creates the models we wish to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQrZq5PAe5my",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "0d900ad0-8e56-4aec-a918-254337a04ce6"
      },
      "source": [
        "# compare standalone models for binary classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['lr'] = LogisticRegression()\n",
        "\tmodels['knn'] = KNeighborsClassifier()\n",
        "\tmodels['cart'] = DecisionTreeClassifier()\n",
        "\tmodels['svm'] = SVC()\n",
        "\tmodels['bayes'] = GaussianNB()\n",
        "\treturn models\n",
        "\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">lr 0.866 (0.029)\n",
            ">knn 0.931 (0.025)\n",
            ">cart 0.825 (0.046)\n",
            ">svm 0.957 (0.020)\n",
            ">bayes 0.833 (0.031)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5zTQyT4D9yX",
        "colab_type": "text"
      },
      "source": [
        "`SVM` performs the best with about `95.7` percent mean accuracy.\n",
        "\n",
        "A box-and-whisker plot is then created comparing the distribution accuracy scores for each model, allowing us to clearly see that KNN and `SVM` perform better on average than LR, CART, and Bayes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6KczN6gFWbG",
        "colab_type": "text"
      },
      "source": [
        "Next, we can try to `combine these five models` into `a single ensemble model using stacking.`\n",
        "\n",
        "We can use a logistic regression model to learn how to best combine the predictions from each of the separate five models.\n",
        "\n",
        "The  [get_stacking() function](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html) below defines the `StackingClassifier` model by first defining a list of tuples for the five base models, then defining the logistic regression meta-model to combine the predictions from the base models using 5-fold cross-validation.\n",
        "\n",
        "Our expectation is that the stacking ensemble will perform better than any single base model.\n",
        "\n",
        "This is not always the case and if it is not the case, then the base model should be used in favor of the ensemble model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ArqqdvEPFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "52f109a3-e5f8-4b8d-d0a3-0ba88f85ff96"
      },
      "source": [
        "# compare ensemble to each baseline classifier\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
        "\treturn X, y\n",
        "\n",
        "# get a stacking ensemble of models\n",
        "def get_stacking():\n",
        "\t# define the base models\n",
        "\tlevel0 = list()\n",
        "\tlevel0.append(('lr', LogisticRegression()))\n",
        "\tlevel0.append(('knn', KNeighborsClassifier()))\n",
        "\tlevel0.append(('cart', DecisionTreeClassifier()))\n",
        "\tlevel0.append(('svm', SVC()))\n",
        "\tlevel0.append(('bayes', GaussianNB()))\n",
        "\t# define meta learner model\n",
        "\tlevel1 = LogisticRegression()\n",
        "\t# define the stacking ensemble\n",
        "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "\treturn model\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['lr'] = LogisticRegression()\n",
        "\tmodels['knn'] = KNeighborsClassifier()\n",
        "\tmodels['cart'] = DecisionTreeClassifier()\n",
        "\tmodels['svm'] = SVC()\n",
        "\tmodels['bayes'] = GaussianNB()\n",
        "\tmodels['stacking'] = get_stacking()\n",
        "\treturn models\n",
        "\n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">lr 0.866 (0.029)\n",
            ">knn 0.931 (0.025)\n",
            ">cart 0.826 (0.039)\n",
            ">svm 0.957 (0.020)\n",
            ">bayes 0.833 (0.031)\n",
            ">stacking 0.964 (0.018)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IiZngutJ75U",
        "colab_type": "text"
      },
      "source": [
        "If we choose a stacking ensemble as our final model, we can fit and use it to make predictions on new data just like any other model.\n",
        "\n",
        "First, the stacking ensemble is fit on all available data, then the predict() function can be called to make predictions on new data.\n",
        "\n",
        "The example below demonstrates this on our binary classification dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tpE5coeJ-EJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca7cda1d-ba6d-4801-8bbd-d376280758ee"
      },
      "source": [
        "# make a prediction with a stacking ensemble\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
        "# define the base models\n",
        "level0 = list()\n",
        "level0.append(('lr', LogisticRegression()))\n",
        "level0.append(('knn', KNeighborsClassifier()))\n",
        "level0.append(('cart', DecisionTreeClassifier()))\n",
        "level0.append(('svm', SVC()))\n",
        "level0.append(('bayes', GaussianNB()))\n",
        "# define meta learner model\n",
        "level1 = LogisticRegression()\n",
        "# define the stacking ensemble\n",
        "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "# fit the model on all available data\n",
        "model.fit(X, y)\n",
        "# make a prediction for one example\n",
        "data = [[2.47475454,0.40165523,1.68081787,2.88940715,0.91704519,-3.07950644,4.39961206,0.72464273,-4.86563631,-6.06338084,-1.22209949,-0.4699618,1.01222748,-0.6899355,-0.53000581,6.86966784,-3.27211075,-6.59044146,-2.21290585,-3.139579]]\n",
        "yhat = model.predict(data)\n",
        "print('Predicted Class: %d' % (yhat))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e3q9bZze6X0",
        "colab_type": "text"
      },
      "source": [
        "### 4. Stacking for Regression\n",
        "\n",
        "In this section, we will look at using stacking for a regression problem.\n",
        "\n",
        "First, we can use the make_regression() [function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) to create a synthetic regression problem with 1,000 examples and 20 input features.\n",
        "\n",
        "Specifically, we will evaluate the following three algorithms:\n",
        "\n",
        "* k-Nearest Neighbors.\n",
        "* Decision Tree.\n",
        "* Support Vector Regressio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj2OUomye_BL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "e7fce472-98b5-452f-f742-934a6ec71927"
      },
      "source": [
        "# compare machine learning models for regression\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['knn'] = KNeighborsRegressor()\n",
        "\tmodels['cart'] = DecisionTreeRegressor()\n",
        "\tmodels['svm'] = SVR()\n",
        "\treturn models\n",
        "\n",
        "# evaluate a given model using  repeated k-fold cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">knn -101.019 (7.161)\n",
            ">cart -148.460 (11.787)\n",
            ">svm -162.419 (12.565)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fADE1KkIKmrh",
        "colab_type": "text"
      },
      "source": [
        "Here we have three different algorithms that perform well, presumably in different ways on this dataset.\n",
        "\n",
        "Next, we can try to combine these three models into a single ensemble model using stacking.\n",
        "\n",
        "We can `use a linear regression model` to learn how to best `combine the predictions` from each of the separate three models.\n",
        "\n",
        "The get_stacking() `function` below defines the [StackingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html) model by first defining a list of tuples for the three base models, then defining the linear regression meta-model to combine the predictions from the base models using `5-fold cross-validation`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Rdyb2bKiO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "d1e0a019-234f-4375-85d8-679fb8f5de61"
      },
      "source": [
        "# compare ensemble to each standalone models for regression\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
        "\treturn X, y\n",
        "\n",
        "# get a stacking ensemble of models\n",
        "def get_stacking():\n",
        "\t# define the base models\n",
        "\tlevel0 = list()\n",
        "\tlevel0.append(('knn', KNeighborsRegressor()))\n",
        "\tlevel0.append(('cart', DecisionTreeRegressor()))\n",
        "\tlevel0.append(('svm', SVR()))\n",
        "\t# define meta learner model\n",
        "\tlevel1 = LinearRegression()\n",
        "\t# define the stacking ensemble\n",
        "\tmodel = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
        "\treturn model\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['knn'] = KNeighborsRegressor()\n",
        "\tmodels['cart'] = DecisionTreeRegressor()\n",
        "\tmodels['svm'] = SVR()\n",
        "\tmodels['stacking'] = get_stacking()\n",
        "\treturn models\n",
        "\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">knn -101.019 (7.161)\n",
            ">cart -147.185 (10.837)\n",
            ">svm -162.419 (12.565)\n",
            ">stacking -56.696 (5.223)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggB_kVhQLFxC",
        "colab_type": "text"
      },
      "source": [
        "If we choose a stacking ensemble as our final model, we can fit and use it to make predictions on new data just like any other model.\n",
        "\n",
        "First, the stacking ensemble is fit on all available data, then the `predict() function` can be called to make predictions on new data.\n",
        "\n",
        "The example below demonstrates this on our regression dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pMF3wAxK6L-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ec3d17d-7706-4921-acc0-63601173b43f"
      },
      "source": [
        "# make a prediction with a stacking ensemble\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
        "# define the base models\n",
        "level0 = list()\n",
        "level0.append(('knn', KNeighborsRegressor()))\n",
        "level0.append(('cart', DecisionTreeRegressor()))\n",
        "level0.append(('svm', SVR()))\n",
        "# define meta learner model\n",
        "level1 = LinearRegression()\n",
        "# define the stacking ensemble\n",
        "model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
        "# fit the model on all available data\n",
        "model.fit(X, y)\n",
        "# make a prediction for one example\n",
        "data = [[0.59332206,-0.56637507,1.34808718,-0.57054047,-0.72480487,1.05648449,0.77744852,0.07361796,0.88398267,2.02843157,1.01902732,0.11227799,0.94218853,0.26741783,0.91458143,-0.72759572,1.08842814,-0.61450942,-0.69387293,1.69169009]]\n",
        "yhat = model.predict(data)\n",
        "print('Predicted Value: %.3f' % (yhat))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Value: 556.980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwbRN6_IO08s",
        "colab_type": "text"
      },
      "source": [
        "#### Further Reading\n",
        "\n",
        "* How to Implement Stacked Generalization (Stacking) From Scratch With Python [link](https://machinelearningmastery.com/implementing-stacking-scratch-python/)\n",
        "* How to Develop a Stacking Ensemble for Deep Learning Neural Networks in Python With Keras [link](https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/)\n",
        "* How to Develop Super Learner Ensembles in Python [link](https://machinelearningmastery.com/super-learner-ensemble-in-python/)\n",
        "* How to Use Out-of-Fold Predictions in Machine Learning [link](https://machinelearningmastery.com/out-of-fold-predictions-in-machine-learning/)\n",
        "* A Gentle Introduction to k-fold Cross-Validation [link](https://machinelearningmastery.com/k-fold-cross-validation/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKvhWqbFK-ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}